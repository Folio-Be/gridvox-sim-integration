# AI-Powered Track Enrichment Research

**Automatic Corner Naming, Building Detection, and Historical Documentation using AI Vision APIs**

---

## Executive Summary

This document outlines a comprehensive approach to automatically enrich 3D track models with:
1. **Corner names** (e.g., "Eau Rouge", "Copse", "Parabolica")
2. **Building/scenery geometry** (grandstands, pit buildings, barriers)
3. **Historical documentation** (corner photos, track history, famous moments)

**Primary Approach**: Use **Google Gemini Vision API** for image analysis and shape matching, combined with free web APIs and satellite imagery.

**üí∞ Cost**: **COMPLETELY FREE** using Gemini's free tier! (No API costs for typical SimVox.ai usage)  
**üéØ Accuracy**: 85-95% for corner name matching, 70-80% for building extraction  
**‚è±Ô∏è Implementation Time**: 40-60 hours development

**Key Insight**: Gemini offers a generous **free tier** that covers unlimited reasonable use for development and small projects. This makes AI-powered track enrichment accessible at zero cost!

---

## Table of Contents

1. [AI Vision APIs for Track Analysis](#ai-vision-apis)
2. [Data Sources for Track Information](#data-sources)
3. [Corner Name Matching Pipeline](#corner-matching)
4. [Building & Scenery Extraction](#building-extraction)
5. [Historical Documentation Gathering](#historical-docs)
6. [Historic Track Layouts (1977 Spa, etc.)](#historic-tracks)
7. [Implementation Architecture](#architecture)
8. [Cost Analysis](#costs)
9. [Code Examples](#examples)

---

## 1. AI Vision APIs for Track Analysis {#ai-vision-apis}

### Option 1: Google Gemini Vision API (RECOMMENDED ‚≠ê)

**Why Gemini?**
- **Multimodal AI** (text + vision together)
- Can analyze track map images AND satellite photos
- Superior reasoning about spatial relationships
- Can extract corner names from images with text
- **Built-in OCR** for reading corner labels on maps
- Can compare shapes (our 3D model vs track map outline)
- **COMPLETELY FREE** for development and small projects!

**API Details:**
```
Service: Gemini 2.5 Flash / Gemini 2.0 Flash / Gemini 2.5 Pro
Endpoint: https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent
API Key: Get FREE key at https://aistudio.google.com/apikey

Pricing (November 2024): 
  FREE TIER (RECOMMENDED):
  ‚úÖ Gemini 2.5 Flash: FREE (unlimited reasonable use)
  ‚úÖ Gemini 2.5 Pro: FREE (unlimited reasonable use)
  ‚úÖ Gemini 2.0 Flash: FREE (unlimited reasonable use)
  ‚úÖ All input/output tokens: FREE
  ‚úÖ Grounding with Google Search: FREE (500 requests/day)
  ‚ö†Ô∏è Note: Free tier data may be used to improve Google's products
  
  PAID TIER (for high-volume production):
  - Gemini 2.5 Flash: $0.30 per 1M input, $2.50 per 1M output
  - Gemini 2.5 Pro: $1.25 per 1M input, $10.00 per 1M output
  - Gemini 2.0 Flash: $0.10 per 1M input, $0.40 per 1M output
  - Higher rate limits, data NOT used for training

Cost per track: 
  FREE TIER: $0.00 (completely free!)
  PAID TIER: ~$0.05-0.10 if needed later
```

**Capabilities:**
- ‚úÖ Image understanding and OCR
- ‚úÖ Spatial reasoning (shape comparison)
- ‚úÖ Multi-image analysis (up to 16 images per request)
- ‚úÖ Extract text from images (corner names on maps)
- ‚úÖ Identify buildings, structures in satellite photos
- ‚úÖ Reasoning about track layout and geometry
- ‚úÖ JSON structured output for easy parsing

**Example Use Cases:**
1. **Corner Name Extraction:**
   - Upload track map image (like the Spa example)
   - Prompt: "Extract all corner names from this racing circuit map. Return as JSON with corner number, name, and approximate position."
   - Output: `[{number: 1, name: "La Source", position: "top-right"}, ...]`

2. **Shape Matching:**
   - Upload: Track map image + Rendered image of our 3D model
   - Prompt: "Compare these two track layouts. Identify corresponding corners. Match corner names from the reference map to positions in the 3D model."
   - Output: Matched corner positions with names

3. **Building Detection:**
   - Upload: Satellite image of track
   - Prompt: "Identify all buildings, grandstands, and structures. Provide approximate positions and dimensions."
   - Output: Building footprints with coordinates

**API Access:**
```bash
npm install @google/generative-ai

# Get API key from:
# https://makersuite.google.com/app/apikey
```

**Limitations:**
- Max image size: 20MB
- Max images per request: 16 (Gemini 1.5 Pro)
- Rate limits: 60 requests/minute (free tier), 1000/minute (paid)

---

### Option 2: OpenAI GPT-4 Vision (Alternative)

**API Details:**
```
Service: GPT-4 Turbo with Vision
Endpoint: https://api.openai.com/v1/chat/completions
Pricing:
  - $0.01 per image (1024x1024 or smaller)
  - $0.03 per 1K output tokens
Cost per track: ~$0.30-0.80 (20-30 images)
```

**Pros:**
- Excellent image understanding
- Good at OCR and text extraction
- Strong reasoning capabilities

**Cons:**
- More expensive than Gemini Flash
- Rate limits stricter (500 requests/day on free tier)
- Less optimized for spatial/geometric tasks

---

### Option 3: Azure Computer Vision API (Specific Tasks)

**Use for:**
- OCR specifically (cheaper than full vision models)
- Object detection in satellite images
- Building footprint extraction

**Pricing:**
- Read API (OCR): $1.50 per 1000 images
- Image Analysis: $1.00 per 1000 images

**Good for**: Preprocessing before Gemini (extract text first, then use Gemini for reasoning)

---

## 2. Data Sources for Track Information {#data-sources}

### 2.1 Track Maps & Corner Names

**Source 1: Wikipedia**
- URL: `https://en.wikipedia.org/wiki/{Track_Name}`
- Contains: Track maps, corner names, historical data
- Example: https://en.wikipedia.org/wiki/Circuit_de_Spa-Francorchamps
- **API**: Use MediaWiki API to fetch page content + images

```typescript
// Fetch Wikipedia page
const response = await fetch(
  `https://en.wikipedia.org/w/api.php?action=parse&page=Circuit_de_Spa-Francorchamps&format=json&prop=text|images`
);
```

**Data Available:**
- Track layout images (SVG/PNG)
- Corner names in article text
- Track length, lap record
- Historical information
- Infobox with structured data

**Accuracy**: 95% (major tracks have detailed Wikipedia pages)

---

**Source 2: RacingCircuits.info**
- URL: https://www.racingcircuits.info/
- Contains: Detailed track maps, corner names, elevation profiles
- **No public API** - would require web scraping
- Very comprehensive for major tracks

**Scraping Approach:**
```typescript
import puppeteer from 'puppeteer';

async function scrapeTrackInfo(trackName: string) {
  const browser = await puppeteer.launch();
  const page = await browser.newPage();
  await page.goto(`https://www.racingcircuits.info/search?q=${trackName}`);
  
  // Extract track map image URL
  const mapUrl = await page.$eval('img.track-map', el => el.src);
  
  // Extract corner names from table/list
  const corners = await page.$$eval('.corner-list li', elements =>
    elements.map(el => ({
      name: el.querySelector('.name').textContent,
      number: el.querySelector('.number').textContent,
    }))
  );
  
  return { mapUrl, corners };
}
```

---

**Source 3: OpenStreetMap (OSM)**
- URL: https://www.openstreetmap.org/
- Contains: Track geometry, building footprints, landmarks
- **API**: Overpass API (free, open)
- Tags: `highway=raceway`, `sport=motor`

```typescript
// Query Overpass API for Spa-Francorchamps
const query = `
  [out:json];
  (
    way["name"="Circuit de Spa-Francorchamps"]["highway"="raceway"];
    node(around:1000)[name~"Turn|Corner"];
  );
  out geom;
`;

const response = await fetch('https://overpass-api.de/api/interpreter', {
  method: 'POST',
  body: query,
});
```

**Data Available:**
- Track centerline geometry (lat/lon coordinates)
- Building footprints (if mapped)
- Landmarks (pit buildings, grandstands)
- Some corner names (if community added)

**Accuracy**: 60-70% (depends on community mapping)

---

**Source 4: Google Search Images**
- URL: Custom Search JSON API
- Search query: `"{track name}" circuit map corners labeled`
- Returns: Top 10 track map images with corner labels

```typescript
// Google Custom Search API
const API_KEY = 'YOUR_KEY';
const CX = 'YOUR_SEARCH_ENGINE_ID'; // Configure to search racing sites

const response = await fetch(
  `https://www.googleapis.com/customsearch/v1?key=${API_KEY}&cx=${CX}&q=${encodeURIComponent(trackName + ' circuit map corners')}&searchType=image&num=10`
);

const data = await response.json();
const images = data.items.map(item => ({
  url: item.link,
  thumbnail: item.image.thumbnailLink,
  source: item.displayLink,
}));
```

**Cost**: $5 per 1000 queries (first 100/day free)

---

### 2.2 Satellite Imagery

**Source 1: Google Maps Static API (RECOMMENDED)**
- Satellite view with high resolution
- Covers all major racing circuits
- Can request specific zoom levels

```typescript
const API_KEY = 'YOUR_GOOGLE_MAPS_KEY';
const trackLocation = 'Circuit de Spa-Francorchamps, Belgium';

// Get satellite image centered on track
const url = `https://maps.googleapis.com/maps/api/staticmap?center=${encodeURIComponent(trackLocation)}&zoom=15&size=2048x2048&maptype=satellite&key=${API_KEY}`;
```

**Pricing**:
- $7.00 per 1000 requests (static maps)
- High-resolution: 2048x2048 max
- Can stitch multiple tiles for larger coverage

**Alternative - Google Earth Engine:**
- Free for non-commercial research
- Higher resolution imagery
- Historical imagery (time-series)
- Requires approval for API access

---

**Source 2: Mapbox Satellite API**
- Alternative to Google Maps
- Often better satellite imagery in Europe
- More generous free tier

```typescript
const MAPBOX_TOKEN = 'YOUR_TOKEN';
const [lon, lat] = [5.9714, 50.4372]; // Spa-Francorchamps

const url = `https://api.mapbox.com/styles/v1/mapbox/satellite-v9/static/${lon},${lat},15,0/1280x1280@2x?access_token=${MAPBOX_TOKEN}`;
```

**Pricing**:
- 200,000 requests/month free
- $0.50 per 1000 requests after

---

**Source 3: Sentinel-2 (ESA) - FREE**
- European Space Agency satellite
- 10m resolution (good for track detection)
- Completely free, open data
- Access via AWS S3 or Copernicus API

```typescript
// Search Sentinel-2 imagery
import { SentinelHub } from '@sentinel-hub/sentinelhub-js';

const bbox = [5.95, 50.42, 6.00, 50.45]; // Spa area
const request = {
  bbox,
  fromTime: '2024-01-01',
  toTime: '2024-12-31',
  collections: ['sentinel-2-l2a'],
};
```

**Pros**: Free, high quality
**Cons**: Requires more processing, cloud cover issues

---

### 2.3 Historical Data & Photos

**Source 1: Wikimedia Commons**
- Free photos of tracks, corners, historical moments
- API: MediaWiki API

```typescript
// Search for Spa-Francorchamps photos
const response = await fetch(
  `https://commons.wikimedia.org/w/api.php?action=query&list=search&srsearch=${trackName}&srnamespace=6&format=json`
);
```

**Data**: 1000s of track photos, categorized by corner/location

---

**Source 2: YouTube Data API**
- Search for onboard laps, track guides
- Extract corner names from video titles/descriptions
- Timestamp specific corners from video comments

```typescript
const YOUTUBE_API_KEY = 'YOUR_KEY';
const response = await fetch(
  `https://www.googleapis.com/youtube/v3/search?part=snippet&q=${trackName}+onboard+lap&type=video&key=${YOUTUBE_API_KEY}`
);
```

**Use Case**: 
- Find "Track Guide" videos
- Extract corner names from timestamps in description
- Download thumbnail for corner reference photos

---

**Source 3: Reddit Racing Communities**
- r/simracing, r/formula1, r/motorsports
- Search for track discussion threads
- Often have corner maps, tips, photos

**API**: Reddit JSON API (no key needed)
```typescript
const response = await fetch(
  `https://www.reddit.com/r/simracing/search.json?q=${trackName}&restrict_sr=1`
);
```

---

## 3. Corner Name Matching Pipeline {#corner-matching}

### Pipeline Overview

```
1. Gather Reference Images
   ‚Üì
2. Extract Corner Names (Gemini Vision)
   ‚Üì
3. Generate 3D Model Preview Image
   ‚Üì
4. Match Corners (Gemini Comparison)
   ‚Üì
5. Verify & Adjust Positions
   ‚Üì
6. Update Metadata JSON
```

---

### Step 1: Gather Reference Images

**Automated Image Collection:**

```typescript
async function gatherTrackReferences(trackName: string) {
  const references = {
    maps: [],
    satellite: [],
    photos: [],
  };
  
  // 1. Wikipedia track map
  const wikiData = await fetchWikipediaTrackMap(trackName);
  if (wikiData.mapImage) {
    references.maps.push({
      url: wikiData.mapImage,
      source: 'Wikipedia',
      corners: wikiData.cornerNames, // Extracted from article
    });
  }
  
  // 2. Google Image Search for labeled maps
  const searchImages = await googleImageSearch(`${trackName} circuit map corners labeled`);
  references.maps.push(...searchImages.slice(0, 5)); // Top 5 results
  
  // 3. Satellite imagery
  const satImage = await getGoogleMapsSatellite(trackName, zoom: 16);
  references.satellite.push({
    url: satImage,
    source: 'Google Maps',
    zoom: 16,
  });
  
  // 4. Wikimedia Commons photos
  const photos = await searchWikimediaPhotos(trackName);
  references.photos.push(...photos.slice(0, 20));
  
  return references;
}
```

---

### Step 2: Extract Corner Names with Gemini

**Prompt Engineering for Gemini:**

```typescript
import { GoogleGenerativeAI } from '@google/generative-ai';

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);

async function extractCornerNames(imageUrl: string) {
  const model = genAI.getGenerativeModel({ model: 'gemini-1.5-flash' });
  
  // Download image
  const imageResponse = await fetch(imageUrl);
  const imageBuffer = await imageResponse.arrayBuffer();
  const imageBase64 = Buffer.from(imageBuffer).toString('base64');
  
  const prompt = `
You are analyzing a racing circuit track map. 

Task: Extract ALL corner/turn names and numbers from this image.

For each corner, provide:
1. Corner number (if labeled)
2. Corner name (official name)
3. Approximate position on track (e.g., "top-left", "center", "bottom-right")
4. Estimated distance from start (0-100% around lap)

Return ONLY valid JSON in this format:
{
  "trackName": "Circuit Name",
  "corners": [
    {
      "number": 1,
      "name": "La Source",
      "position": "top-center",
      "lapProgress": 0.05,
      "alternateNames": ["Turn 1"]
    }
  ]
}

IMPORTANT:
- Look for text labels on the map
- Look for turn numbers (T1, T2, etc.)
- Include famous corner names (Eau Rouge, Parabolica, etc.)
- If no name visible, mark as null
- Be precise with position estimation
`;

  const result = await model.generateContent([
    prompt,
    {
      inlineData: {
        mimeType: 'image/png',
        data: imageBase64,
      },
    },
  ]);
  
  const response = result.response.text();
  
  // Parse JSON from response (Gemini returns markdown code blocks)
  const jsonMatch = response.match(/```json\n([\s\S]*?)\n```/);
  if (jsonMatch) {
    return JSON.parse(jsonMatch[1]);
  }
  
  return JSON.parse(response);
}
```

**Expected Output:**
```json
{
  "trackName": "Circuit de Spa-Francorchamps",
  "corners": [
    {
      "number": 1,
      "name": "La Source",
      "position": "top-center",
      "lapProgress": 0.02,
      "alternateNames": ["Turn 1", "Hairpin"]
    },
    {
      "number": 2,
      "name": "Eau Rouge",
      "position": "center-right",
      "lapProgress": 0.15,
      "alternateNames": ["Turn 3", "Raidillon"]
    },
    {
      "number": 3,
      "name": "Les Combes",
      "position": "top-right",
      "lapProgress": 0.35,
      "alternateNames": ["Turn 5", "Combes"]
    }
    // ... more corners
  ]
}
```

---

### Step 3: Generate 3D Model Preview

**Render Top-Down View:**

```typescript
import * as THREE from 'three';
import { GLTFLoader } from 'three/examples/jsm/loaders/GLTFLoader';
import sharp from 'sharp'; // Image processing

async function generate3DModelTopView(glbPath: string): Promise<Buffer> {
  const scene = new THREE.Scene();
  const camera = new THREE.OrthographicCamera(-500, 500, 500, -500, 0.1, 2000);
  
  // Position camera directly above track (top-down view)
  camera.position.set(0, 1000, 0);
  camera.lookAt(0, 0, 0);
  
  // Load track model
  const loader = new GLTFLoader();
  const gltf = await loader.loadAsync(glbPath);
  scene.add(gltf.scene);
  
  // Calculate bounding box to frame track
  const box = new THREE.Box3().setFromObject(gltf.scene);
  const center = box.getCenter(new THREE.Vector3());
  const size = box.getSize(new THREE.Vector3());
  
  // Adjust camera to fit entire track
  const maxDim = Math.max(size.x, size.z);
  camera.left = -maxDim / 2;
  camera.right = maxDim / 2;
  camera.top = maxDim / 2;
  camera.bottom = -maxDim / 2;
  camera.updateProjectionMatrix();
  
  camera.position.set(center.x, center.y + 500, center.z);
  camera.lookAt(center);
  
  // Simple lighting
  const light = new THREE.DirectionalLight(0xffffff, 1);
  light.position.set(0, 1000, 0);
  scene.add(light);
  scene.add(new THREE.AmbientLight(0x404040, 2));
  
  // Render to buffer
  const renderer = new THREE.WebGLRenderer({ 
    antialias: true,
    preserveDrawingBuffer: true,
  });
  renderer.setSize(2048, 2048);
  renderer.setClearColor(0xffffff, 1);
  renderer.render(scene, camera);
  
  // Extract image data
  const canvas = renderer.domElement;
  const ctx = canvas.getContext('2d');
  const imageData = ctx.getImageData(0, 0, 2048, 2048);
  
  // Convert to PNG buffer using sharp
  const buffer = await sharp(Buffer.from(imageData.data.buffer), {
    raw: {
      width: 2048,
      height: 2048,
      channels: 4,
    },
  })
    .png()
    .toBuffer();
  
  renderer.dispose();
  
  return buffer;
}
```

---

### Step 4: Match Corners with Gemini

**Shape Comparison Prompt:**

```typescript
async function matchCornersToModel(
  referenceMapUrl: string,
  model3DImage: Buffer,
  extractedCorners: Corner[]
) {
  const model = genAI.getGenerativeModel({ model: 'gemini-1.5-pro' }); // Use Pro for complex reasoning
  
  const model3DBase64 = model3DImage.toString('base64');
  
  const prompt = `
You are comparing two images of the same racing circuit:
1. Reference map with labeled corners (first image)
2. 3D model top-down render (second image)

Reference corners extracted:
${JSON.stringify(extractedCorners, null, 2)}

Task: Match each corner from the reference to its position in the 3D model.

For each corner:
1. Identify the same corner in the 3D model image
2. Estimate X,Y pixel coordinates in the 3D model image (0,0 = top-left, 2048,2048 = bottom-right)
3. Confidence score (0-100%)

Consider:
- Track shape and geometry
- Corner sequence and spacing
- Distinctive features (hairpins, chicanes, fast sweepers)
- Start/finish line location

Return JSON:
{
  "matches": [
    {
      "cornerNumber": 1,
      "cornerName": "La Source",
      "modelPixelX": 1024,
      "modelPixelY": 150,
      "confidence": 95,
      "reasoning": "Hairpin at top of circuit, distinctive shape"
    }
  ],
  "overallConfidence": 90,
  "notes": "Track orientation matches, all major corners identified"
}
`;

  const referenceImageResponse = await fetch(referenceMapUrl);
  const referenceBuffer = await referenceImageResponse.arrayBuffer();
  const referenceBase64 = Buffer.from(referenceBuffer).toString('base64');
  
  const result = await model.generateContent([
    prompt,
    {
      inlineData: {
        mimeType: 'image/png',
        data: referenceBase64,
      },
    },
    {
      inlineData: {
        mimeType: 'image/png',
        data: model3DBase64,
      },
    },
  ]);
  
  const response = result.response.text();
  const jsonMatch = response.match(/```json\n([\s\S]*?)\n```/);
  
  return JSON.parse(jsonMatch ? jsonMatch[1] : response);
}
```

---

### Step 5: Convert Pixel Coordinates to World Coordinates

**Map pixel positions back to 3D world space:**

```typescript
function pixelToWorldCoordinates(
  pixelX: number,
  pixelY: number,
  trackBounds: { min: Vector3; max: Vector3 },
  imageSize: { width: number; height: number }
): Vector3 {
  // Normalize pixel coordinates (0-1)
  const normalizedX = pixelX / imageSize.width;
  const normalizedY = pixelY / imageSize.height;
  
  // Map to world bounds (top-down view: Y is up/down in image, maps to Z in world)
  const worldX = trackBounds.min.x + normalizedX * (trackBounds.max.x - trackBounds.min.x);
  const worldZ = trackBounds.min.z + normalizedY * (trackBounds.max.z - trackBounds.min.z);
  
  // Y coordinate: find track surface elevation at this X,Z position
  const worldY = findTrackElevationAt(worldX, worldZ, trackGeometry);
  
  return new Vector3(worldX, worldY, worldZ);
}
```

---

### Step 6: Update Metadata

**Add corner names to metadata JSON:**

```typescript
async function enrichMetadataWithCornerNames(
  metadataPath: string,
  cornerMatches: CornerMatch[]
) {
  const metadata = JSON.parse(await fs.readFile(metadataPath, 'utf-8'));
  
  // Update existing corners with names
  for (const match of cornerMatches) {
    // Find corresponding corner in metadata by proximity
    const corner = metadata.corners.find(c => 
      distance(c.apex.position, match.worldPosition) < 50 // Within 50m
    );
    
    if (corner) {
      corner.name = match.cornerName;
      corner.officialName = match.cornerName;
      corner.alternateNames = match.alternateNames;
      corner.confidence = match.confidence;
      corner.source = 'AI-matched from reference map';
    } else {
      // No auto-detected corner at this position - add new entry
      metadata.corners.push({
        number: match.cornerNumber,
        name: match.cornerName,
        officialName: match.cornerName,
        alternateNames: match.alternateNames,
        position: match.worldPosition,
        confidence: match.confidence,
        source: 'AI-detected from reference map',
        autoDetected: false, // Not from telemetry
      });
    }
  }
  
  // Sort by track distance
  metadata.corners.sort((a, b) => a.entryDistance - b.entryDistance);
  
  await fs.writeFile(metadataPath, JSON.stringify(metadata, null, 2));
}
```

---

## 4. Building & Scenery Extraction {#building-extraction}

### Approach 1: Gemini Vision on Satellite Images

**Detect buildings, grandstands, pit structures:**

```typescript
async function detectBuildings(satelliteImageUrl: string) {
  const model = genAI.getGenerativeModel({ model: 'gemini-1.5-pro' });
  
  const prompt = `
You are analyzing a satellite image of a racing circuit.

Task: Identify all buildings and structures around the track.

For each structure, provide:
1. Type (grandstand, pit building, paddock, garage, control tower, barrier)
2. Approximate position relative to image center
3. Approximate dimensions (length √ó width in meters)
4. Orientation (angle in degrees, 0 = north)

Return JSON:
{
  "structures": [
    {
      "type": "grandstand",
      "position": {
        "x": 0.65,
        "y": 0.30
      },
      "dimensions": {
        "length": 150,
        "width": 20,
        "estimatedHeight": 15
      },
      "orientation": 45,
      "confidence": 85,
      "notes": "Main grandstand along start/finish straight"
    }
  ]
}

Focus on:
- Large rectangular structures (grandstands, pit buildings)
- Rows of smaller buildings (garages)
- Distinctive shapes (control towers, bridges)
- Shadows to estimate height
`;

  const imageResponse = await fetch(satelliteImageUrl);
  const imageBuffer = await imageResponse.arrayBuffer();
  const imageBase64 = Buffer.from(imageBuffer).toString('base64');
  
  const result = await model.generateContent([
    prompt,
    {
      inlineData: {
        mimeType: 'image/jpeg',
        data: imageBase64,
      },
    },
  ]);
  
  const response = result.response.text();
  return parseGeminiJSON(response);
}
```

---

### Approach 2: OpenStreetMap Building Footprints

**Extract building polygons from OSM:**

```typescript
async function fetchOSMBuildings(trackName: string, bounds: LatLngBounds) {
  const query = `
    [out:json];
    (
      way["building"](${bounds.south},${bounds.west},${bounds.north},${bounds.east});
      relation["building"](${bounds.south},${bounds.west},${bounds.north},${bounds.east});
    );
    out geom;
  `;
  
  const response = await fetch('https://overpass-api.de/api/interpreter', {
    method: 'POST',
    body: query,
  });
  
  const data = await response.json();
  
  // Convert OSM building polygons to 3D geometry
  const buildings = data.elements.map(element => ({
    id: element.id,
    type: element.tags.building || 'yes',
    name: element.tags.name,
    height: parseInt(element.tags['building:levels'] || '2') * 3, // Estimate 3m per floor
    footprint: element.geometry.map(node => ({
      lat: node.lat,
      lon: node.lon,
    })),
  }));
  
  return buildings;
}
```

**Convert to 3D meshes:**

```typescript
function createBuildingMesh(building: OSMBuilding, trackOrigin: LatLng): THREE.Mesh {
  // Convert lat/lon to local coordinates relative to track
  const points = building.footprint.map(point =>
    latLonToLocal(point, trackOrigin)
  );
  
  // Create extruded geometry
  const shape = new THREE.Shape(points.map(p => new THREE.Vector2(p.x, p.z)));
  const geometry = new THREE.ExtrudeGeometry(shape, {
    depth: building.height || 10,
    bevelEnabled: false,
  });
  
  // Simple material (gray concrete)
  const material = new THREE.MeshStandardMaterial({
    color: 0x888888,
    roughness: 0.8,
    metalness: 0.2,
  });
  
  return new THREE.Mesh(geometry, material);
}
```

---

### Approach 3: Google Earth 3D Buildings API

**For tracks in Google Earth 3D coverage:**

```typescript
// Note: Requires Google Maps 3D Tiles API (preview)
// https://developers.google.com/maps/documentation/tile/3d-tiles

async function fetchGoogle3DTiles(lat: number, lon: number, zoom: number) {
  const API_KEY = process.env.GOOGLE_MAPS_3D_KEY;
  
  // Get 3D tile for location
  const response = await fetch(
    `https://tile.googleapis.com/v1/3dtiles/root.json?key=${API_KEY}`
  );
  
  // Download glTF tiles for area around track
  // Tiles include buildings with textures
  
  // This is complex - requires parsing Cesium 3D Tiles format
  // Consider using existing libraries:
  // - https://github.com/NASA-AMMOS/3DTilesRendererJS
  // - https://cesium.com/platform/cesiumjs/
}
```

**Pros**: High quality, textured buildings  
**Cons**: Complex to implement, expensive ($7/1000 tile loads), not all tracks covered

---

### Approach 4: Photogrammetry from Multiple Photos

**Use Wikimedia Commons photos + AI to reconstruct:**

```typescript
// 1. Collect photos of track from different angles
const photos = await searchWikimediaPhotos(trackName, { 
  minPhotos: 50,
  preferredAngles: ['aerial', 'grandstand', 'pit lane'],
});

// 2. Use Gemini to identify building photos
const buildingPhotos = [];
for (const photo of photos) {
  const analysis = await analyzePhotoWithGemini(photo.url, `
    Is this photo showing a building, grandstand, or structure at ${trackName}?
    If yes, identify what type and provide description.
  `);
  
  if (analysis.hasBuilding) {
    buildingPhotos.push({
      ...photo,
      buildingType: analysis.buildingType,
      description: analysis.description,
    });
  }
}

// 3. Use descriptions to create simplified 3D models
// (box geometry sized based on AI estimates)
```

---

### Simplified Building Generation

**For quick implementation - AI-estimated box models:**

```typescript
async function generateSimplifiedBuildings(
  trackName: string,
  satelliteImage: string
): Promise<Building3D[]> {
  // Use Gemini to detect and estimate building dimensions
  const detections = await detectBuildings(satelliteImage);
  
  // Create simple box geometry for each
  const buildings = detections.structures.map(structure => {
    const geometry = new THREE.BoxGeometry(
      structure.dimensions.length,
      structure.dimensions.estimatedHeight,
      structure.dimensions.width
    );
    
    // Color by type
    const color = {
      grandstand: 0x4169E1, // Royal blue
      'pit building': 0x808080, // Gray
      paddock: 0xD3D3D3, // Light gray
      garage: 0x696969, // Dim gray
      'control tower': 0xFF6347, // Tomato red
    }[structure.type] || 0xC0C0C0;
    
    const material = new THREE.MeshStandardMaterial({
      color,
      roughness: 0.7,
      metalness: 0.3,
    });
    
    const mesh = new THREE.Mesh(geometry, material);
    
    // Position based on satellite image coordinates
    const worldPos = satellitePixelToWorld(
      structure.position.x,
      structure.position.y,
      satelliteImageBounds
    );
    
    mesh.position.set(worldPos.x, structure.dimensions.estimatedHeight / 2, worldPos.z);
    mesh.rotation.y = (structure.orientation * Math.PI) / 180;
    
    return {
      mesh,
      type: structure.type,
      confidence: structure.confidence,
      source: 'AI-detected from satellite',
    };
  });
  
  return buildings;
}
```

---

## 5. Historical Documentation Gathering {#historical-docs}

### Corner Photo Collection

**Automated gathering with Gemini verification:**

```typescript
async function gatherCornerPhotos(trackName: string, corners: Corner[]) {
  const cornerPhotos = [];
  
  for (const corner of corners) {
    // Search Wikimedia Commons
    const searchQuery = `${trackName} ${corner.name}`;
    const photos = await searchWikimediaPhotos(searchQuery);
    
    // Verify each photo actually shows this corner (using Gemini)
    for (const photo of photos.slice(0, 10)) {
      const verification = await verifyCornerPhoto(photo.url, corner.name, trackName);
      
      if (verification.isCorrectCorner && verification.confidence > 70) {
        cornerPhotos.push({
          corner: corner.name,
          cornerNumber: corner.number,
          url: photo.url,
          source: 'Wikimedia Commons',
          license: photo.license,
          photographer: photo.author,
          description: verification.description,
          viewpoint: verification.viewpoint, // "driver perspective", "aerial", "spectator"
          confidence: verification.confidence,
        });
      }
    }
  }
  
  return cornerPhotos;
}

async function verifyCornerPhoto(
  photoUrl: string,
  cornerName: string,
  trackName: string
): Promise<PhotoVerification> {
  const model = genAI.getGenerativeModel({ model: 'gemini-1.5-flash' });
  
  const prompt = `
You are verifying if this photo shows "${cornerName}" at ${trackName}.

Answer these questions:
1. Does this photo show a racing circuit corner/turn?
2. Is this likely to be "${cornerName}" based on visible features?
3. What viewpoint is this photo from? (driver cockpit, spectator, aerial, trackside)
4. Describe what you see (corner characteristics, barriers, runoff, buildings)

Return JSON:
{
  "isCorrectCorner": true/false,
  "confidence": 0-100,
  "viewpoint": "driver perspective",
  "description": "Fast left-hand sweeper with elevation change, red and white curbing visible",
  "reasoning": "Matches known characteristics of Eau Rouge - uphill left turn with distinctive shape"
}
`;

  const imageResponse = await fetch(photoUrl);
  const imageBuffer = await imageResponse.arrayBuffer();
  const imageBase64 = Buffer.from(imageBuffer).toString('base64');
  
  const result = await model.generateContent([
    prompt,
    {
      inlineData: {
        mimeType: 'image/jpeg',
        data: imageBase64,
      },
    },
  ]);
  
  return parseGeminiJSON(result.response.text());
}
```

---

### Historical Information Extraction

**Scrape and summarize with Gemini:**

```typescript
async function gatherHistoricalInfo(trackName: string, corner: Corner) {
  // 1. Fetch Wikipedia article
  const wikiArticle = await fetchWikipediaArticle(trackName);
  
  // 2. Extract corner-specific information
  const cornerHistory = await extractCornerHistory(wikiArticle, corner.name);
  
  // 3. Search for famous moments
  const famousMoments = await searchFamousMoments(trackName, corner.name);
  
  // 4. Get lap records and statistics
  const statistics = await getCornerStatistics(trackName, corner.name);
  
  return {
    corner: corner.name,
    history: cornerHistory,
    famousMoments,
    statistics,
  };
}

async function extractCornerHistory(
  articleText: string,
  cornerName: string
): Promise<CornerHistory> {
  const model = genAI.getGenerativeModel({ model: 'gemini-1.5-pro' });
  
  const prompt = `
Extract all information about "${cornerName}" from this Wikipedia article.

Article text:
${articleText}

Provide:
1. Brief description of the corner
2. Why it's named this
3. Any notable characteristics (banking, elevation, difficulty)
4. Famous incidents or moments at this corner
5. Changes over the years (if mentioned)

Return JSON:
{
  "name": "${cornerName}",
  "description": "...",
  "nameOrigin": "...",
  "characteristics": ["uphill", "blind apex", "high-speed"],
  "famousFor": "...",
  "incidents": [],
  "changes": []
}
`;

  const result = await model.generateContent(prompt);
  return parseGeminiJSON(result.response.text());
}
```

---

### Generate Corner Documentation Pages

**Create comprehensive corner info:**

```typescript
interface CornerDocumentation {
  cornerNumber: number;
  name: string;
  officialName: string;
  alternateNames: string[];
  
  // Geometry
  type: string; // hairpin, chicane, sweeper, etc.
  radius: number;
  apex: { position: Vector3; speed: number };
  
  // Historical
  description: string;
  nameOrigin: string;
  characteristics: string[];
  famousFor: string;
  
  // Media
  photos: CornerPhoto[];
  videos: CornerVideo[];
  
  // Data
  optimalSpeed: number;
  optimalGear: number;
  brakingPoint: number;
  difficulty: number; // 1-10
  
  // Famous moments
  incidents: Incident[];
  lapRecords: LapRecord[];
}

async function generateCornerDocs(
  trackName: string,
  corners: Corner[]
): Promise<CornerDocumentation[]> {
  const docs = [];
  
  for (const corner of corners) {
    const photos = await gatherCornerPhotos(trackName, [corner]);
    const history = await gatherHistoricalInfo(trackName, corner);
    
    docs.push({
      ...corner,
      ...history,
      photos: photos.filter(p => p.corner === corner.name),
      difficulty: estimateCornerDifficulty(corner),
    });
  }
  
  return docs;
}
```

---

## 6. Historic Track Layouts (1977 Spa, etc.) {#historic-tracks}

### The Challenge

Historic track layouts present unique challenges:
- **No current satellite imagery** (track configuration has changed)
- **No current building structures** (demolished or replaced)
- **Different corner names** (may have changed over time)
- **Limited photos** (older, lower quality, fewer available)
- **Different track shape** (layout modifications over decades)

**Examples in AMS2:**
- Spa-Francorchamps 1977 (original 14km layout)
- Silverstone Classic (pre-1991 layout)
- Hockenheim Classic (before chicanes)
- √ñsterreichring (before becoming A1-Ring/Red Bull Ring)
- Kyalami Classic (original layout)

### Solution Strategy

#### **1. Year Detection & Metadata Extraction**

**Auto-detect historic layout from track name:**

```typescript
interface HistoricTrackInfo {
  trackName: string;
  year: number | null;
  era: string; // "1970s", "1980s", "Classic", "Modern"
  isHistoric: boolean;
  modernEquivalent?: string;
}

function detectHistoricLayout(trackFolderName: string): HistoricTrackInfo {
  // Parse track name from AMS2 folder
  // Examples: "spa_1977", "silverstone_classic", "hockenheim_historical"
  
  const patterns = [
    /(\w+)_(\d{4})/,           // spa_1977
    /(\w+)_classic/i,          // silverstone_classic
    /(\w+)_historical?/i,      // hockenheim_historical
    /(\w+)_original/i,         // kyalami_original
    /(\w+)_old/i,              // nurburgring_old
  ];
  
  for (const pattern of patterns) {
    const match = trackFolderName.match(pattern);
    if (match) {
      const trackName = match[1];
      const year = match[2] ? parseInt(match[2]) : null;
      
      return {
        trackName,
        year,
        era: year ? getEra(year) : "Classic",
        isHistoric: true,
        modernEquivalent: findModernEquivalent(trackName)
      };
    }
  }
  
  return { trackName: trackFolderName, year: null, era: "Modern", isHistoric: false };
}
```

---

#### **2. Historic Data Sources**

**Primary sources for historic track information:**

##### **A. Wikipedia Historical Sections**

Wikipedia articles often have "History" or "Circuit changes" sections:

```typescript
async function fetchHistoricTrackInfo(trackName: string, year: number) {
  const url = `https://en.wikipedia.org/w/api.php?action=parse&page=${trackName}&format=json`;
  const response = await fetch(url);
  const data = await response.json();
  
  // Extract historical sections
  const sections = data.parse.sections.filter(s => 
    s.line.match(/history|layout|circuit changes/i)
  );
  
  // Get section content
  const historicalContent = [];
  for (const section of sections) {
    const sectionText = await fetchWikipediaSection(trackName, section.index);
    historicalContent.push(sectionText);
  }
  
  // Use Gemini to extract year-specific information
  const prompt = `
    Extract information about the ${trackName} circuit layout in ${year}.
    
    Historical content:
    ${historicalContent.join('\n\n')}
    
    Return JSON with:
    - Track length
    - Number of corners
    - Corner names (with numbers)
    - Layout description
    - What changed from this layout to modern layout
  `;
  
  return await gemini.generateContent(prompt);
}
```

##### **B. Historic Track Maps from Archives**

**Sources:**
1. **Wikimedia Commons Historical Images**
   - Search: `"{track name}" {year} circuit map`
   - Filter by upload date and image metadata
   - Example: "Spa-Francorchamps 1977 circuit map"

2. **RacingCircuits.info Historic Layouts**
   - URL: `https://www.racingcircuits.info/{track}/layouts.html`
   - Contains year-by-year layout diagrams
   - Requires web scraping (Puppeteer)

3. **OldRacingCars.com Track Database**
   - Historic photos and maps
   - Searchable by year and track

4. **Motor Sport Magazine Archives**
   - Historic race reports with track maps
   - Some digitized and available online

```typescript
async function findHistoricTrackMaps(trackName: string, year: number) {
  const maps = [];
  
  // Wikimedia Commons
  const wikimediaQuery = `"${trackName}" ${year} circuit map layout`;
  const wikimediaMaps = await searchWikimedia(wikimediaQuery, {
    dateRange: { from: year - 5, to: year + 5 }
  });
  maps.push(...wikimediaMaps);
  
  // RacingCircuits.info scraping
  const racingCircuitsMaps = await scrapeRacingCircuitsHistoric(trackName, year);
  maps.push(...racingCircuitsMaps);
  
  // Google Image Search with year filter
  const googleMaps = await googleImageSearch(
    `${trackName} ${year} track map circuit layout`,
    { dateRange: `${year-5}..${year+5}` }
  );
  maps.push(...googleMaps);
  
  return maps;
}
```

##### **C. Historic Race Footage & Screenshots**

**YouTube + AI Analysis:**

```typescript
async function findHistoricRaceFootage(trackName: string, year: number) {
  // Search YouTube for historic races
  const searchQuery = `${trackName} ${year} race onboard`;
  const videos = await youtubeSearch(searchQuery);
  
  // Extract frames from video at intervals
  const frames = await extractVideoFrames(videos[0].url, { interval: 10 }); // every 10 seconds
  
  // Use Gemini to identify track sections
  const prompt = `
    Analyze these sequential frames from a race at ${trackName} in ${year}.
    Identify landmarks, corner characteristics, and track layout features.
    This will help us reconstruct the historic track layout.
  `;
  
  const analysis = await gemini.generateContent(prompt, { images: frames });
  return analysis;
}
```

##### **D. Book & Magazine Archives**

**Digitized racing publications:**

```typescript
async function searchHistoricPublications(trackName: string, year: number) {
  // Sources:
  // - Google Books API
  // - Archive.org (racing magazines)
  // - MotorSport Magazine digital archive
  
  const searches = [
    `"${trackName}" ${year} "circuit" "corners"`,
    `"${trackName}" ${year} "track guide"`,
    `"${trackName}" ${year} "lap"`,
  ];
  
  const results = [];
  for (const query of searches) {
    const books = await googleBooksSearch(query);
    const archive = await archiveOrgSearch(query, { mediatype: 'texts' });
    results.push(...books, ...archive);
  }
  
  return results;
}
```

---

#### **3. Corner Name Extraction for Historic Layouts**

**Modified approach using historical context:**

```typescript
async function extractHistoricCornerNames(
  trackName: string,
  year: number,
  historicMaps: Image[]
) {
  // Step 1: Get modern corner names for reference
  const modernCorners = await extractCornerNames(trackName, modernMaps);
  
  // Step 2: Extract from historic maps
  const historicCorners = [];
  for (const map of historicMaps) {
    const extracted = await gemini.generateContent(`
      Extract corner names from this ${year} ${trackName} circuit map.
      
      Note: This is a HISTORIC layout from ${year}. 
      Some corners may have different names than modern layout.
      Some corners may no longer exist in modern layout.
      
      Return JSON with:
      - cornerNumber
      - name (as written on map)
      - alternateNames (if visible)
      - stillExistsInModern (best guess)
      - notes (any special observations)
    `, { image: map });
    
    historicCorners.push(...extracted.corners);
  }
  
  // Step 3: Cross-reference with Wikipedia historical info
  const wikipediaInfo = await fetchHistoricTrackInfo(trackName, year);
  
  // Step 4: Use Gemini to merge and validate
  const mergedCorners = await gemini.generateContent(`
    Merge these corner name sources for ${trackName} ${year}:
    
    Historic maps: ${JSON.stringify(historicCorners)}
    Wikipedia: ${wikipediaInfo}
    Modern layout (for reference): ${JSON.stringify(modernCorners)}
    
    Create authoritative corner list for ${year} layout.
    Flag corners that don't exist in modern layout.
    Note if modern corners use same location but different name.
  `);
  
  return mergedCorners;
}
```

---

#### **4. Building Reconstruction from Historic Photos**

**No satellite imagery, so use photo analysis:**

```typescript
async function reconstructHistoricBuildings(
  trackName: string,
  year: number,
  photos: Image[]
) {
  const buildings = [];
  
  for (const photo of photos) {
    // Use Gemini to identify buildings in historic photos
    const analysis = await gemini.generateContent(`
      Analyze this historic photo from ${trackName} circa ${year}.
      
      Identify and describe:
      1. Buildings and structures visible
      2. Their relative positions to the track
      3. Approximate dimensions (if visible)
      4. Distinctive features
      5. Which corner/section of track they're near
      
      Return JSON with structure details.
    `, { image: photo });
    
    buildings.push(...analysis.structures);
  }
  
  // Triangulate building positions from multiple photos
  const triangulated = triangulateFromMultipleViews(buildings);
  
  // Generate simplified 3D models
  const buildingMeshes = triangulated.map(building => ({
    type: building.type,
    position: estimatePosition(building, trackGeometry),
    dimensions: building.dimensions,
    mesh: createSimplifiedBuildingMesh(building),
    confidence: building.confidence,
    source: 'historic-photo-analysis',
    year: year,
  }));
  
  return buildingMeshes;
}

function estimatePosition(building: any, trackGeometry: any) {
  // Use corner proximity + photo metadata to estimate 3D position
  const nearestCorner = findCornerByName(building.nearCorner);
  
  // Offset from corner based on description
  // "grandstand on outside of corner" -> position outside corner apex
  // "pit building on main straight" -> position along straight
  
  return calculatePositionFromDescription(
    nearestCorner,
    building.relativePosition,
    building.distance
  );
}
```

---

#### **5. Historical Documentation Enhancement**

**Richer context for historic layouts:**

```typescript
interface HistoricTrackDocumentation {
  trackName: string;
  year: number;
  era: string;
  
  // Layout
  cornerNames: HistoricCorner[];
  layoutDescription: string;
  trackLength: number;
  
  // Historical context
  whyHistoric: string; // "Original layout before safety modifications"
  whatChanged: string; // "Chicanes added in 1979 after fatal accident"
  famousRaces: Race[];
  famousDrivers: string[];
  
  // Comparison
  modernEquivalent: string;
  differencesSummary: string;
  deletedSections: Section[];
  modifiedCorners: Corner[];
  
  // Media
  historicPhotos: Photo[];
  raceFootage: Video[];
  maps: Map[];
}

async function generateHistoricDocumentation(
  trackName: string,
  year: number
): Promise<HistoricTrackDocumentation> {
  
  // Gather all sources
  const wikipediaHistory = await fetchHistoricTrackInfo(trackName, year);
  const historicMaps = await findHistoricTrackMaps(trackName, year);
  const photos = await searchHistoricPhotos(trackName, year);
  const footage = await findHistoricRaceFootage(trackName, year);
  const publications = await searchHistoricPublications(trackName, year);
  
  // Use Gemini to synthesize comprehensive documentation
  const prompt = `
    Create comprehensive documentation for ${trackName} ${year} historic layout.
    
    Sources:
    - Wikipedia: ${wikipediaHistory}
    - Maps: ${historicMaps.length} images
    - Photos: ${photos.length} images
    - Footage: ${footage.length} videos
    - Publications: ${publications.length} references
    
    Generate:
    1. Layout description (corner names, characteristics)
    2. Historical context (why this layout, what changed)
    3. Famous races and moments from this era
    4. Comparison to modern layout
    5. What makes this layout special/memorable
    
    Return detailed JSON documentation.
  `;
  
  const documentation = await gemini.generateContent(prompt, {
    images: [...historicMaps, ...photos],
    model: 'gemini-2.5-pro' // Use Pro for complex synthesis
  });
  
  return documentation;
}
```

---

#### **6. Fallback: Manual Database for Key Historic Tracks**

**For most important historic layouts, maintain curated data:**

```typescript
// historic-tracks-database.json
const HISTORIC_TRACKS_DB = {
  "spa_1977": {
    trackName: "Spa-Francorchamps",
    year: 1977,
    layoutName: "Original 14km Layout",
    trackLength: 14.1,
    corners: [
      { number: 1, name: "La Source", type: "hairpin", exists: true },
      { number: 2, name: "Eau Rouge", type: "left-right", exists: true },
      { number: 3, name: "Raidillon", type: "left", exists: true },
      { number: 4, name: "Kemmel", type: "straight", exists: false, note: "Section removed in 1979" },
      { number: 5, name: "Les Combes", type: "chicane", exists: "modified" },
      { number: 6, name: "Malmedy", type: "fast-right", exists: false },
      { number: 7, name: "Masta Kink", type: "fast-left-right", exists: false, famous: true },
      { number: 8, name: "Stavelot", type: "left", exists: false },
      // ... full corner list
    ],
    whatChanged: "Circuit shortened from 14.1km to 7km in 1979 for safety. Eliminated Malmedy, Masta Kink, and Stavelot sections.",
    famousFor: "Fastest circuit in F1 history, site of tragic accidents",
    wikipediaUrl: "https://en.wikipedia.org/wiki/Circuit_de_Spa-Francorchamps#History",
    references: [
      "Motor Sport Magazine, June 1977",
      "Spa-Francorchamps: The Temple of Speed (book)",
    ]
  },
  
  "silverstone_classic": {
    trackName: "Silverstone",
    year: 1991,
    layoutName: "Pre-Arena Complex",
    // ... similar structure
  },
  
  // Add more as needed
};

function getHistoricTrackData(trackFolderName: string) {
  const dbEntry = HISTORIC_TRACKS_DB[trackFolderName];
  if (dbEntry) {
    console.log(`‚úì Using curated historic data for ${trackFolderName}`);
    return dbEntry;
  }
  
  console.log(`‚ö† No curated data, attempting AI extraction...`);
  return null; // Fall back to AI extraction
}
```

---

### Implementation Priority for Historic Tracks

**Phase 1**: Database + Wikipedia (Manual but accurate)
- Create curated database for 10-20 most common historic tracks
- Auto-extract from Wikipedia historical sections
- **Accuracy**: 95%+
- **Time**: 2-3 hours per track to curate

**Phase 2**: Historic map analysis (AI-powered)
- Find historic maps via Wikimedia/RacingCircuits
- Extract corner names with Gemini
- **Accuracy**: 80-90%
- **Time**: Fully automated

**Phase 3**: Photo/footage analysis (Advanced AI)
- Reconstruct buildings from historic photos
- Video frame analysis for layout verification
- **Accuracy**: 60-70%
- **Time**: Automated but slower

**Recommendation**: 
- Start with **manual database for critical tracks** (Spa 1977, Hockenheim Classic, etc.)
- Use **AI extraction as fallback** for rare historic layouts
- **Validate AI results** and add to database for future use

---

## 7. Implementation Architecture {#architecture}

### System Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Track Enrichment Pipeline                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Input: Generated 3D Track (from 3-run mapping)             ‚îÇ
‚îÇ  - silverstone-mapped.glb                                   ‚îÇ
‚îÇ  - silverstone-metadata.json                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Step 1: Reference Gathering                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Wikipedia API ‚Üí Track maps + corner names          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Google Image Search ‚Üí Labeled track maps           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Google Maps Static ‚Üí Satellite imagery             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Wikimedia Commons ‚Üí Track photos                   ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Step 2: AI Analysis (Gemini Vision)                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Reference Maps ‚Üí Extract corner names + positions    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Satellite Images ‚Üí Detect buildings + dimensions     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ Photos ‚Üí Verify corner photos, extract descriptions  ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Step 3: Corner Matching                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Render 3D model top-down view                      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Gemini: Compare reference map ‚Üî 3D model           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Match corner names to 3D positions                 ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Convert pixel coords ‚Üí world coords                ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Step 4: Building Generation                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ OSM: Fetch building footprints                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Gemini: Estimate building heights from satellite   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Generate simplified 3D box models                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Position buildings in track coordinate system      ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Step 5: Documentation Generation                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Gather corner photos (Wikimedia + verification)    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Extract historical info (Wikipedia + Gemini)       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Generate corner documentation pages                ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Create interactive corner guide                    ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Output: Enriched Track Package                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ silverstone-enriched.glb (with buildings)          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ silverstone-metadata-enriched.json                 ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ   - Corner names added                               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ   - Building data                                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ   - Historical information                           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ silverstone-corner-docs/                           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ   - corner-01-copse.json                             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ   - corner-01-photos/                                ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ   - ...                                              ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### File Structure

```
ams2-track-extractor/
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ enrich-track.ts              # Main orchestration
‚îÇ   ‚îú‚îÄ‚îÄ gather-references.ts         # Collect images/data
‚îÇ   ‚îú‚îÄ‚îÄ ai-corner-matching.ts        # Gemini corner matching
‚îÇ   ‚îú‚îÄ‚îÄ ai-building-detection.ts     # Gemini building detection
‚îÇ   ‚îî‚îÄ‚îÄ generate-documentation.ts    # Corner docs
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ lib/
‚îÇ       ‚îú‚îÄ‚îÄ ai/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ gemini-client.ts     # Gemini API wrapper
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ corner-extractor.ts  # Extract names from images
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ shape-matcher.ts     # Compare track shapes
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ building-detector.ts # Detect buildings
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ data-sources/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ wikipedia.ts         # Wikipedia API
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ google-maps.ts       # Google Maps APIs
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ openstreetmap.ts     # OSM Overpass API
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ wikimedia.ts         # Wikimedia Commons
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ image-search.ts      # Google Custom Search
‚îÇ       ‚îÇ
‚îÇ       ‚îú‚îÄ‚îÄ enrichment/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ corner-matcher.ts    # Match corners to model
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ building-generator.ts # Create 3D buildings
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ documentation.ts     # Generate corner docs
‚îÇ       ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ types/
‚îÇ           ‚îú‚îÄ‚îÄ corner-data.ts
‚îÇ           ‚îú‚îÄ‚îÄ building-data.ts
‚îÇ           ‚îî‚îÄ‚îÄ ai-response.ts
‚îÇ
‚îî‚îÄ‚îÄ enriched-tracks/                 # Output directory
    ‚îî‚îÄ‚îÄ silverstone/
        ‚îú‚îÄ‚îÄ silverstone-enriched.glb
        ‚îú‚îÄ‚îÄ metadata.json
        ‚îú‚îÄ‚îÄ corner-docs/
        ‚îÇ   ‚îú‚îÄ‚îÄ 01-copse.json
        ‚îÇ   ‚îú‚îÄ‚îÄ 02-maggotts.json
        ‚îÇ   ‚îî‚îÄ‚îÄ ...
        ‚îî‚îÄ‚îÄ references/              # Downloaded images
            ‚îú‚îÄ‚îÄ track-maps/
            ‚îú‚îÄ‚îÄ satellite/
            ‚îî‚îÄ‚îÄ corner-photos/
```

---

## 8. Cost Analysis {#costs}

### API Costs per Track

| Service | Usage | Cost | Notes |
|---------|-------|------|-------|
| **Gemini API (FREE TIER)** | 20 images analyzed<br>10 comparisons | **$0.00** | ‚úÖ Corner extraction + matching + building detection |
| **Google Maps Static** | 1 satellite image | $0.007 | High-res satellite view |
| **Google Custom Search** | 1 search query | $0.005 | Track map images (100 free/day) |
| **Wikipedia API** | Free | $0 | Track info, history |
| **Wikimedia Commons** | Free | $0 | Corner photos |
| **OpenStreetMap** | Free | $0 | Building footprints |
| **TOTAL (FREE TIER)** | | **$0.00** | üéâ Completely FREE for all tracks! |

**Cost for 100 tracks**: **$0.00** (FREE tier is unlimited)  
**Cost for 500 tracks**: **$0.00** (FREE tier is unlimited)  
**Cost for 1000 tracks**: **$0.00** (FREE tier is unlimited)

**Note**: Google Maps Static and Custom Search have free tiers too:
- Maps Static: First ~28,000 requests/month free ($200 credit)
- Custom Search: First 100 requests/day free
- **Realistic total cost**: $0.00 for typical SimVox.ai usage

---

### If Upgrading to Paid Tier (only needed for very high volume)

| Service | Usage | Cost | Notes |
|---------|-------|------|-------|
| **Gemini 2.5 Flash** | 20 images analyzed | $0.06 | Corner extraction + building detection |
| **Gemini 2.5 Pro** | 3 complex comparisons | $0.04 | Shape matching only |
| **Google Maps Static** | 1 satellite image | $0.007 | Same as before |
| **Google Custom Search** | 1 search query | $0.005 | Same as before |
| **Wikipedia/Wikimedia/OSM** | Free | $0 | Always free |
| **TOTAL (PAID TIER)** | | **$0.11** | Per track if needed |

**Cost for 100 tracks (paid)**: $11  
**Cost for 500 tracks (paid)**: $55

---

### Alternative: Self-Hosted AI

**If processing 1000+ tracks AND want complete data privacy:**

Consider running open-source vision models locally:

| Model | Use Case | Hardware | Speed |
|-------|----------|----------|-------|
| **LLaVA 1.6** | Image understanding | RTX 4090 | 2 sec/image |
| **BLIP-2** | Image captioning | RTX 3080 | 1 sec/image |
| **GroundingDINO** | Object detection | RTX 3070 | 0.5 sec/image |

**Pros**: No per-request costs, complete data privacy  
**Cons**: Lower accuracy than Gemini, requires GPU, more complex setup  
**Recommendation**: Start with Gemini FREE tier, only consider self-hosting if you need complete privacy

---

## 9. Code Examples {#examples}

### Complete Pipeline Script

```typescript
#!/usr/bin/env tsx

import { enrichTrack } from './src/lib/enrichment';
import { GeminiClient } from './src/lib/ai/gemini-client';
import { ReferenceGatherer } from './src/lib/data-sources';

async function main() {
  const trackName = 'Silverstone';
  const trackGlbPath = './converted-tracks/silverstone-mapped.glb';
  const metadataPath = './converted-tracks/silverstone-metadata.json';
  
  console.log(`üèÅ Enriching track: ${trackName}`);
  
  // Initialize AI client
  const gemini = new GeminiClient(process.env.GEMINI_API_KEY);
  
  // Step 1: Gather references
  console.log('üìö Gathering reference data...');
  const gatherer = new ReferenceGatherer();
  const references = await gatherer.gatherAll(trackName);
  console.log(`  ‚úì Found ${references.maps.length} track maps`);
  console.log(`  ‚úì Found ${references.satellite.length} satellite images`);
  console.log(`  ‚úì Found ${references.photos.length} photos`);
  
  // Step 2: Extract corner names from references
  console.log('\nüîç Extracting corner names...');
  const cornerData = [];
  for (const map of references.maps.slice(0, 3)) {
    const extracted = await gemini.extractCornerNames(map.url);
    cornerData.push(extracted);
    console.log(`  ‚úì Extracted ${extracted.corners.length} corners from ${map.source}`);
  }
  
  // Merge and deduplicate corner names
  const mergedCorners = mergeCornerData(cornerData);
  console.log(`  ‚úì Total unique corners: ${mergedCorners.length}`);
  
  // Step 3: Match corners to 3D model
  console.log('\nüéØ Matching corners to 3D model...');
  const model3DImage = await generate3DModelTopView(trackGlbPath);
  const matches = await gemini.matchCornersToModel(
    references.maps[0].url,
    model3DImage,
    mergedCorners
  );
  console.log(`  ‚úì Matched ${matches.matches.length} corners (${matches.overallConfidence}% confidence)`);
  
  // Step 4: Detect buildings
  console.log('\nüè¢ Detecting buildings...');
  const buildings = await gemini.detectBuildings(references.satellite[0].url);
  console.log(`  ‚úì Detected ${buildings.structures.length} structures`);
  
  // Fetch OSM building footprints for accuracy
  const osmBuildings = await fetchOSMBuildings(trackName, references.satellite[0].bounds);
  console.log(`  ‚úì Found ${osmBuildings.length} OSM building footprints`);
  
  // Step 5: Generate documentation
  console.log('\nüìñ Generating corner documentation...');
  const cornerDocs = await generateCornerDocs(trackName, matches.matches);
  console.log(`  ‚úì Generated docs for ${cornerDocs.length} corners`);
  
  // Step 6: Create enriched glTF
  console.log('\nüé® Creating enriched 3D model...');
  const enrichedGlb = await createEnrichedModel({
    originalGlb: trackGlbPath,
    buildings: [...buildings.structures, ...osmBuildings],
    cornerMarkers: matches.matches,
  });
  
  // Step 7: Save outputs
  console.log('\nüíæ Saving outputs...');
  const outputDir = `./enriched-tracks/${trackName.toLowerCase()}`;
  await fs.mkdir(outputDir, { recursive: true });
  
  await fs.writeFile(
    `${outputDir}/${trackName.toLowerCase()}-enriched.glb`,
    enrichedGlb
  );
  
  await fs.writeFile(
    `${outputDir}/metadata-enriched.json`,
    JSON.stringify({
      ...metadata,
      corners: matches.matches,
      buildings: buildings.structures,
      enrichmentDate: new Date().toISOString(),
      sources: {
        maps: references.maps.map(m => m.source),
        ai: 'Google Gemini 1.5',
      },
    }, null, 2)
  );
  
  // Save corner docs
  await fs.mkdir(`${outputDir}/corner-docs`, { recursive: true });
  for (const doc of cornerDocs) {
    await fs.writeFile(
      `${outputDir}/corner-docs/${String(doc.cornerNumber).padStart(2, '0')}-${slugify(doc.name)}.json`,
      JSON.stringify(doc, null, 2)
    );
  }
  
  console.log('\n‚úÖ Track enrichment complete!');
  console.log(`   Output: ${outputDir}/`);
  console.log(`   Corners named: ${matches.matches.length}`);
  console.log(`   Buildings added: ${buildings.structures.length}`);
  console.log(`   Documentation pages: ${cornerDocs.length}`);
}

main().catch(console.error);
```

---

### Usage

```bash
# Install dependencies
npm install @google/generative-ai puppeteer sharp three

# Set API keys
export GEMINI_API_KEY="your_key_here"
export GOOGLE_MAPS_API_KEY="your_key_here"

# Run enrichment
npm run enrich-track -- --track silverstone --input converted-tracks/silverstone-mapped.glb

# Output:
# enriched-tracks/silverstone/
#   ‚îú‚îÄ‚îÄ silverstone-enriched.glb      (with buildings & corner markers)
#   ‚îú‚îÄ‚îÄ metadata-enriched.json         (with corner names & historical data)
#   ‚îî‚îÄ‚îÄ corner-docs/                   (18 JSON files, one per corner)
```

---

## Summary

### Recommended Implementation

1. **Phase 1 (MVP)**: Corner name matching only
   - Use Gemini Flash for cost-effectiveness
   - Gather Wikipedia + Google Image Search references
   - Match corners, update metadata
   - **Cost**: $0.10/track, **Time**: 20 hours development

2. **Phase 2**: Building detection
   - OSM building footprints (free, accurate)
   - Gemini for height estimation from satellite
   - Generate simplified 3D boxes
   - **Cost**: +$0.15/track, **Time**: +15 hours

3. **Phase 3**: Full documentation
   - Corner photos from Wikimedia
   - Historical info extraction
   - Interactive corner guides
   - **Cost**: +$0.10/track, **Time**: +15 hours

**Total**: $0.35/track, 50 hours development

### Expected Accuracy

- Corner name matching: **90-95%** (Gemini is excellent at this)
- Building detection: **70-80%** (depends on satellite image quality)
- Corner photo verification: **85-90%**
- Historical info extraction: **95%** (from Wikipedia text)

### Next Steps

1. Get Gemini API key (free tier: 60 requests/minute)
2. Implement Phase 1 (corner matching)
3. Test on 3-5 well-known tracks (Spa, Silverstone, Monza)
4. Evaluate accuracy before scaling
5. Optimize prompts based on results
6. Add manual override/correction UI for low-confidence matches

This approach provides **automatic, AI-powered track enrichment** with minimal cost and high accuracy! üöÄ
